Speech processing plays an important role in any speech system whether its Automatic Speech Recog nition (ASR) or speaker recognition or something else. Mel-Frequency Cepstral Coefficients (MFCCs) were very important feature in the procecss of ASR. To get MFCCs features, a signal goes through a pre-emphasis filter; then gets sliced into (overlapping) frames and a window function is applied to each frame; afterwards, we do a Fourier transform on each frame (or more specifically a Short-Time Fourier Transform) and calculate the power spectrum; and subsequently compute the filter banks. To obtain MFCCs, a Discrete Cosine Transform (DCT) is applied to the filter banks retaining a number of the resulting coefficients while the rest are discarded. A final step in both cases, is mean normalization.

Given a collection of parameterised audio files, where each parameter vector is labelled with either voice or silence, build a VAD system based on feed-forward neural network architecture and measure its performance using EER criterion. In order to relax strict independence assumptions consider appending a range of previous and following feature vectors such that the modified form of feature vector. As a complement, or alternative to, feed-forward neural network build a recurrent form of neural networks. Measure performance on development and test data using EER criterion.
